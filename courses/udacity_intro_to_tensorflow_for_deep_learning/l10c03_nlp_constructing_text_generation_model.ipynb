{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "punL79CN7Ox6"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "_ckMIh7O7s6D"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ph5eir3Pf-3z"
      },
      "source": [
        "# Constructing a Text Generation Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5Uhzt6vVIB2"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l10c03_nlp_constructing_text_generation_model.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l10c03_nlp_constructing_text_generation_model.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GbGfr_oLCat"
      },
      "source": [
        "Using most of the techniques you've already learned, it's now possible to generate new text by predicting the next word that follows a given seed word. To practice this method, we'll use the [Kaggle Song Lyrics Dataset](https://www.kaggle.com/mousehead/songlyrics)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aHK2CYygXom"
      },
      "source": [
        "## Import TensorFlow and related functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2LmLTREBf5ng"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Other imports for processing data\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmLTO_dpgge9"
      },
      "source": [
        "## Get the Dataset\n",
        "\n",
        "As noted above, we'll utilize the [Song Lyrics dataset](https://www.kaggle.com/mousehead/songlyrics) on Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4Bf5FVHfganK",
        "outputId": "5ee75b35-51a8-4fd1-f0e4-745f3085e652",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-11 06:26:36--  https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8\n",
            "Resolving drive.google.com (drive.google.com)... 142.250.4.139, 142.250.4.101, 142.250.4.138, ...\n",
            "Connecting to drive.google.com (drive.google.com)|142.250.4.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/jhjghnisl9la0ogr1o23rf107aqmcmhu/1681194375000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8?uuid=7b6c135e-5abe-4925-97b4-f3bae91a2d61 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-04-11 06:26:40--  https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/jhjghnisl9la0ogr1o23rf107aqmcmhu/1681194375000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8?uuid=7b6c135e-5abe-4925-97b4-f3bae91a2d61\n",
            "Resolving doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)... 142.251.12.132, 2404:6800:4003:c11::84\n",
            "Connecting to doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)|142.251.12.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 72436445 (69M) [text/csv]\n",
            "Saving to: ‘/tmp/songdata.csv’\n",
            "\n",
            "/tmp/songdata.csv   100%[===================>]  69.08M  70.0MB/s    in 1.0s    \n",
            "\n",
            "2023-04-11 06:26:41 (70.0 MB/s) - ‘/tmp/songdata.csv’ saved [72436445/72436445]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8 \\\n",
        "    -O /tmp/songdata.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gu1BTzMIS1oy"
      },
      "source": [
        "## **First 10 Songs**\n",
        "\n",
        "Let's first look at just 10 songs from the dataset, and see how things perform."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmb9rGaAUDO-"
      },
      "source": [
        "### Preprocessing\n",
        "\n",
        "Let's perform some basic preprocessing to get rid of punctuation and make everything lowercase. We'll then split the lyrics up by line and tokenize the lyrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2AVAvyF_Vuh5"
      },
      "outputs": [],
      "source": [
        "def tokenize_corpus(corpus, num_words=-1):\n",
        "  # Fit a Tokenizer on the corpus\n",
        "  if num_words > -1:\n",
        "    tokenizer = Tokenizer(num_words=num_words)\n",
        "  else:\n",
        "    tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(corpus)\n",
        "  return tokenizer\n",
        "\n",
        "def create_lyrics_corpus(dataset, field):\n",
        "  # Remove all other punctuation\n",
        "  dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n",
        "  # Make it lowercase\n",
        "  dataset[field] = dataset[field].str.lower()\n",
        "  # Make it one long string to split by line\n",
        "  lyrics = dataset[field].str.cat()\n",
        "  corpus = lyrics.split('\\n')\n",
        "  # Remove any trailing whitespace\n",
        "  for l in range(len(corpus)):\n",
        "    corpus[l] = corpus[l].rstrip()\n",
        "  # Remove any empty lines\n",
        "  corpus = [l for l in corpus if l != '']\n",
        "\n",
        "  return corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "apcEXp7WhVBs",
        "outputId": "c3bd66e2-3076-4581-b180-4704a77ff4a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'you': 1, 'i': 2, 'and': 3, 'a': 4, 'me': 5, 'the': 6, 'is': 7, 'my': 8, 'to': 9, 'ma': 10, 'it': 11, 'of': 12, 'im': 13, 'your': 14, 'love': 15, 'so': 16, 'as': 17, 'that': 18, 'in': 19, 'andante': 20, 'boomaboomerang': 21, 'make': 22, 'on': 23, 'oh': 24, 'for': 25, 'but': 26, 'new': 27, 'bang': 28, 'its': 29, 'be': 30, 'like': 31, 'know': 32, 'now': 33, 'how': 34, 'could': 35, 'youre': 36, 'sing': 37, 'never': 38, 'no': 39, 'chiquitita': 40, 'can': 41, 'we': 42, 'song': 43, 'had': 44, 'good': 45, 'youll': 46, 'she': 47, 'just': 48, 'girl': 49, 'again': 50, 'will': 51, 'take': 52, 'please': 53, 'let': 54, 'am': 55, 'eyes': 56, 'was': 57, 'always': 58, 'cassandra': 59, 'blue': 60, 'time': 61, 'dont': 62, 'were': 63, 'return': 64, 'once': 65, 'then': 66, 'sorry': 67, 'cryin': 68, 'over': 69, 'feel': 70, 'ever': 71, 'believe': 72, 'what': 73, 'do': 74, 'go': 75, 'all': 76, 'out': 77, 'think': 78, 'every': 79, 'leave': 80, 'look': 81, 'at': 82, 'way': 83, 'one': 84, 'music': 85, 'down': 86, 'our': 87, 'give': 88, 'learn': 89, 'more': 90, 'us': 91, 'would': 92, 'there': 93, 'before': 94, 'when': 95, 'with': 96, 'feeling': 97, 'play': 98, 'cause': 99, 'away': 100, 'here': 101, 'have': 102, 'yes': 103, 'baby': 104, 'get': 105, 'didnt': 106, 'see': 107, 'did': 108, 'closed': 109, 'realized': 110, 'crazy': 111, 'world': 112, 'lord': 113, 'shes': 114, 'kind': 115, 'without': 116, 'if': 117, 'touch': 118, 'strong': 119, 'making': 120, 'such': 121, 'found': 122, 'true': 123, 'stay': 124, 'together': 125, 'thought': 126, 'come': 127, 'they': 128, 'sweet': 129, 'tender': 130, 'sender': 131, 'tune': 132, 'humdehumhum': 133, 'gonna': 134, 'last': 135, 'leaving': 136, 'sleep': 137, 'only': 138, 'saw': 139, 'tell': 140, 'hes': 141, 'her': 142, 'sound': 143, 'tread': 144, 'lightly': 145, 'ground': 146, 'ill': 147, 'show': 148, 'life': 149, 'too': 150, 'used': 151, 'darling': 152, 'meant': 153, 'break': 154, 'end': 155, 'yourself': 156, 'little': 157, 'dumbedumdum': 158, 'bedumbedumdum': 159, 'youve': 160, 'dumbbedumbdumb': 161, 'bedumbbedumbdumb': 162, 'by': 163, 'theyre': 164, 'alone': 165, 'misunderstood': 166, 'day': 167, 'dawning': 168, 'some': 169, 'wanted': 170, 'none': 171, 'listen': 172, 'words': 173, 'warning': 174, 'darkest': 175, 'nights': 176, 'nobody': 177, 'knew': 178, 'fight': 179, 'caught': 180, 'really': 181, 'power': 182, 'dreams': 183, 'weave': 184, 'until': 185, 'final': 186, 'hour': 187, 'morning': 188, 'ship': 189, 'gone': 190, 'grieving': 191, 'still': 192, 'pain': 193, 'cry': 194, 'sun': 195, 'try': 196, 'face': 197, 'something': 198, 'sees': 199, 'makes': 200, 'fine': 201, 'who': 202, 'mine': 203, 'leaves': 204, 'walk': 205, 'hand': 206, 'well': 207, 'about': 208, 'things': 209, 'slow': 210, 'theres': 211, 'talk': 212, 'why': 213, 'up': 214, 'lousy': 215, 'packing': 216, 'ive': 217, 'gotta': 218, 'near': 219, 'keeping': 220, 'intention': 221, 'growing': 222, 'taking': 223, 'dimension': 224, 'even': 225, 'better': 226, 'thank': 227, 'god': 228, 'not': 229, 'somebody': 230, 'happy': 231, 'question': 232, 'smile': 233, 'mean': 234, 'much': 235, 'kisses': 236, 'around': 237, 'anywhere': 238, 'advice': 239, 'care': 240, 'use': 241, 'selfish': 242, 'tool': 243, 'fool': 244, 'showing': 245, 'boomerang': 246, 'throwing': 247, 'warm': 248, 'kiss': 249, 'surrender': 250, 'giving': 251, 'been': 252, 'door': 253, 'burning': 254, 'bridges': 255, 'being': 256, 'moving': 257, 'though': 258, 'behind': 259, 'are': 260, 'must': 261, 'sure': 262, 'stood': 263, 'hope': 264, 'this': 265, 'deny': 266, 'sad': 267, 'quiet': 268, 'truth': 269, 'heartaches': 270, 'scars': 271, 'dancing': 272, 'sky': 273, 'shining': 274, 'above': 275, 'hear': 276, 'came': 277, 'couldnt': 278, 'everything': 279, 'back': 280, 'long': 281, 'waitin': 282, 'cold': 283, 'chills': 284, 'bone': 285, 'youd': 286, 'wonderful': 287, 'means': 288, 'special': 289, 'smiles': 290, 'lucky': 291, 'fellow': 292, 'park': 293, 'holds': 294, 'squeezes': 295, 'walking': 296, 'hours': 297, 'talking': 298, 'plan': 299, 'easy': 300, 'gently': 301, 'summer': 302, 'evening': 303, 'breeze': 304, 'grow': 305, 'fingers': 306, 'soft': 307, 'light': 308, 'body': 309, 'velvet': 310, 'night': 311, 'soul': 312, 'slowly': 313, 'shimmer': 314, 'thousand': 315, 'butterflies': 316, 'float': 317, 'put': 318, 'rotten': 319, 'boy': 320, 'tough': 321, 'stuff': 322, 'saying': 323, 'need': 324, 'anymore': 325, 'enough': 326, 'standing': 327, 'creep': 328, 'felt': 329, 'cheap': 330, 'notion': 331, 'deep': 332, 'dumb': 333, 'mistake': 334, 'entitled': 335, 'another': 336, 'beg': 337, 'forgive': 338, 'an': 339, 'feels': 340, 'hoot': 341, 'holler': 342, 'mad': 343, 'under': 344, 'heel': 345, 'holy': 346, 'christ': 347, 'deal': 348, 'sick': 349, 'tired': 350, 'tedious': 351, 'ways': 352, 'aint': 353, 'walkin': 354, 'cutting': 355, 'tie': 356, 'wanna': 357, 'into': 358, 'eye': 359, 'myself': 360, 'counting': 361, 'pride': 362, 'unright': 363, 'neighbours': 364, 'ride': 365, 'burying': 366, 'past': 367, 'peace': 368, 'free': 369, 'sucker': 370, 'street': 371, 'singing': 372, 'shouting': 373, 'staying': 374, 'alive': 375, 'city': 376, 'dead': 377, 'hiding': 378, 'their': 379, 'shame': 380, 'hollow': 381, 'laughter': 382, 'while': 383, 'crying': 384, 'bed': 385, 'pity': 386, 'believed': 387, 'lost': 388, 'from': 389, 'start': 390, 'suffer': 391, 'sell': 392, 'secrets': 393, 'bargain': 394, 'playing': 395, 'smart': 396, 'aching': 397, 'hearts': 398, 'sailing': 399, 'father': 400, 'sister': 401, 'reason': 402, 'linger': 403, 'deeply': 404, 'future': 405, 'casting': 406, 'shadow': 407, 'else': 408, 'fate': 409, 'bags': 410, 'thorough': 411, 'knowing': 412, 'late': 413, 'wait': 414, 'watched': 415, 'harbor': 416, 'sunrise': 417, 'sails': 418, 'almost': 419, 'slack': 420, 'cool': 421, 'rain': 422, 'deck': 423, 'tiny': 424, 'figure': 425, 'rigid': 426, 'restrained': 427, 'filled': 428, 'whats': 429, 'wrong': 430, 'enchained': 431, 'own': 432, 'sorrow': 433, 'tomorrow': 434, 'hate': 435, 'shoulder': 436, 'best': 437, 'friend': 438, 'rely': 439, 'broken': 440, 'feather': 441, 'patch': 442, 'walls': 443, 'tumbling': 444, 'loves': 445, 'blown': 446, 'candle': 447, 'seems': 448, 'hard': 449, 'handle': 450, 'id': 451, 'thinking': 452, 'went': 453, 'house': 454, 'hardly': 455, 'guy': 456, 'closing': 457, 'front': 458, 'emptiness': 459, 'he': 460, 'disapeared': 461, 'his': 462, 'car': 463, 'stunned': 464, 'dreamed': 465, 'lifes': 466, 'part': 467, 'move': 468, 'feet': 469, 'pavement': 470, 'acted': 471, 'told': 472, 'lies': 473, 'meet': 474, 'other': 475, 'guys': 476, 'stupid': 477, 'blind': 478, 'smiled': 479, 'took': 480, 'said': 481, 'may': 482, 'couple': 483, 'men': 484, 'them': 485, 'brother': 486, 'joe': 487, 'seeing': 488, 'lot': 489, 'him': 490, 'nice': 491, 'sitting': 492, 'sittin': 493, 'memories': 494}\n",
            "495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-fbdddccf8583>:12: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n",
            "<ipython-input-4-fbdddccf8583>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n",
            "<ipython-input-4-fbdddccf8583>:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dataset[field] = dataset[field].str.lower()\n"
          ]
        }
      ],
      "source": [
        "# Read the dataset from csv - just first 10 songs for now\n",
        "dataset = pd.read_csv('/tmp/songdata.csv', dtype=str)[:10]\n",
        "# Create the corpus using the 'text' column containing lyrics\n",
        "corpus = create_lyrics_corpus(dataset, 'text')\n",
        "# Tokenize the corpus\n",
        "tokenizer = tokenize_corpus(corpus)\n",
        "\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "print(tokenizer.word_index)\n",
        "print(total_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9x68iN_X6FK"
      },
      "source": [
        "### Create Sequences and Labels\n",
        "\n",
        "After preprocessing, we next need to create sequences and labels. Creating the sequences themselves is similar to before with `texts_to_sequences`, but also including the use of [N-Grams](https://towardsdatascience.com/introduction-to-language-models-n-gram-e323081503d9); creating the labels will now utilize those sequences as well as utilize one-hot encoding over all potential output words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QmlTsUqfikVO"
      },
      "outputs": [],
      "source": [
        "sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tsequences.append(n_gram_sequence)\n",
        "\n",
        "# Pad sequences for equal input length \n",
        "max_sequence_len = max([len(seq) for seq in sequences])\n",
        "sequences = np.array(pad_sequences(sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# Split sequences between the \"input\" sequence and \"output\" predicted word\n",
        "input_sequences, labels = sequences[:,:-1], sequences[:,-1]\n",
        "# One-hot encode the labels\n",
        "one_hot_labels = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Zsmu3aEId49i",
        "outputId": "c0c8ab17-91f9-4f40-ecb4-d75bf1276f4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32\n",
            "97\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0  81  82 142 197  29\n",
            "   4]\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0  81  82 142 197  29   4\n",
            " 287]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "# Check out how some of our data is being stored\n",
        "# The Tokenizer has just a single index per word\n",
        "print(tokenizer.word_index['know'])\n",
        "print(tokenizer.word_index['feeling'])\n",
        "# Input sequences will have multiple indexes\n",
        "print(input_sequences[5])\n",
        "print(input_sequences[6])\n",
        "# And the one hot labels will be as long as the full spread of tokenized words\n",
        "print(one_hot_labels[5])\n",
        "print(one_hot_labels[6])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1TAJMlmfO8r"
      },
      "source": [
        "### Train a Text Generation Model\n",
        "\n",
        "Building an RNN to train our text generation model will be very similar to the sentiment models you've built previously. The only real change necessary is to make sure to use Categorical instead of Binary Cross Entropy as the loss function - we could use Binary before since the sentiment was only 0 or 1, but now there are hundreds of categories.\n",
        "\n",
        "From there, we should also consider using *more* epochs than before, as text generation can take a little longer to converge than sentiment analysis, *and* we aren't working with all that much data yet. I'll set it at 200 epochs here since we're only use part of the dataset, and training will tail off quite a bit over that many epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "G1YXuxIqfygN",
        "outputId": "706d0ae9-c7fa-415c-e5fe-b98c79d13049",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "62/62 [==============================] - 15s 93ms/step - loss: 5.9802 - accuracy: 0.0272\n",
            "Epoch 2/200\n",
            "62/62 [==============================] - 2s 32ms/step - loss: 5.4417 - accuracy: 0.0399\n",
            "Epoch 3/200\n",
            "62/62 [==============================] - 1s 18ms/step - loss: 5.3756 - accuracy: 0.0399\n",
            "Epoch 4/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 5.3278 - accuracy: 0.0399\n",
            "Epoch 5/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 5.2574 - accuracy: 0.0394\n",
            "Epoch 6/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 5.1912 - accuracy: 0.0394\n",
            "Epoch 7/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 5.1349 - accuracy: 0.0394\n",
            "Epoch 8/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 5.0793 - accuracy: 0.0409\n",
            "Epoch 9/200\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 5.0119 - accuracy: 0.0525\n",
            "Epoch 10/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 4.9405 - accuracy: 0.0525\n",
            "Epoch 11/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 4.8653 - accuracy: 0.0575\n",
            "Epoch 12/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 4.7888 - accuracy: 0.0641\n",
            "Epoch 13/200\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 4.7156 - accuracy: 0.0681\n",
            "Epoch 14/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.6377 - accuracy: 0.0737\n",
            "Epoch 15/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.5649 - accuracy: 0.0752\n",
            "Epoch 16/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.4924 - accuracy: 0.0832\n",
            "Epoch 17/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 4.4281 - accuracy: 0.0888\n",
            "Epoch 18/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 4.3536 - accuracy: 0.0848\n",
            "Epoch 19/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 4.2857 - accuracy: 0.0984\n",
            "Epoch 20/200\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 4.2214 - accuracy: 0.0943\n",
            "Epoch 21/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.1623 - accuracy: 0.1155\n",
            "Epoch 22/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.1138 - accuracy: 0.1282\n",
            "Epoch 23/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.0499 - accuracy: 0.1367\n",
            "Epoch 24/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.9786 - accuracy: 0.1413\n",
            "Epoch 25/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 3.9215 - accuracy: 0.1493\n",
            "Epoch 26/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.8656 - accuracy: 0.1700\n",
            "Epoch 27/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.8068 - accuracy: 0.1852\n",
            "Epoch 28/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.7458 - accuracy: 0.1988\n",
            "Epoch 29/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.6957 - accuracy: 0.2018\n",
            "Epoch 30/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.6316 - accuracy: 0.2144\n",
            "Epoch 31/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 3.5691 - accuracy: 0.2316\n",
            "Epoch 32/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.5212 - accuracy: 0.2392\n",
            "Epoch 33/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.4711 - accuracy: 0.2503\n",
            "Epoch 34/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.4177 - accuracy: 0.2538\n",
            "Epoch 35/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.3594 - accuracy: 0.2578\n",
            "Epoch 36/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.2940 - accuracy: 0.2856\n",
            "Epoch 37/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.2419 - accuracy: 0.2962\n",
            "Epoch 38/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.1823 - accuracy: 0.3169\n",
            "Epoch 39/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.1340 - accuracy: 0.3350\n",
            "Epoch 40/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 3.0876 - accuracy: 0.3507\n",
            "Epoch 41/200\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 3.0486 - accuracy: 0.3431\n",
            "Epoch 42/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 3.0048 - accuracy: 0.3653\n",
            "Epoch 43/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 2.9504 - accuracy: 0.3890\n",
            "Epoch 44/200\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 2.9022 - accuracy: 0.3804\n",
            "Epoch 45/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.8531 - accuracy: 0.4036\n",
            "Epoch 46/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.8148 - accuracy: 0.4102\n",
            "Epoch 47/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.8022 - accuracy: 0.4102\n",
            "Epoch 48/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.7552 - accuracy: 0.4268\n",
            "Epoch 49/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.6856 - accuracy: 0.4354\n",
            "Epoch 50/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.6336 - accuracy: 0.4390\n",
            "Epoch 51/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.5899 - accuracy: 0.4445\n",
            "Epoch 52/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.5449 - accuracy: 0.4632\n",
            "Epoch 53/200\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 2.5176 - accuracy: 0.4612\n",
            "Epoch 54/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 2.4672 - accuracy: 0.4788\n",
            "Epoch 55/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 2.4210 - accuracy: 0.4884\n",
            "Epoch 56/200\n",
            "62/62 [==============================] - 1s 14ms/step - loss: 2.3949 - accuracy: 0.4929\n",
            "Epoch 57/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 2.3477 - accuracy: 0.5146\n",
            "Epoch 58/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.3127 - accuracy: 0.5161\n",
            "Epoch 59/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.2787 - accuracy: 0.5212\n",
            "Epoch 60/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.2425 - accuracy: 0.5293\n",
            "Epoch 61/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.2314 - accuracy: 0.5237\n",
            "Epoch 62/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.1918 - accuracy: 0.5358\n",
            "Epoch 63/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.1431 - accuracy: 0.5434\n",
            "Epoch 64/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.1018 - accuracy: 0.5590\n",
            "Epoch 65/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 2.0715 - accuracy: 0.5610\n",
            "Epoch 66/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 2.0333 - accuracy: 0.5757\n",
            "Epoch 67/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 2.0061 - accuracy: 0.5812\n",
            "Epoch 68/200\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 1.9696 - accuracy: 0.5863\n",
            "Epoch 69/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.9400 - accuracy: 0.5923\n",
            "Epoch 70/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.9116 - accuracy: 0.5954\n",
            "Epoch 71/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.8858 - accuracy: 0.6009\n",
            "Epoch 72/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.8502 - accuracy: 0.6125\n",
            "Epoch 73/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.8170 - accuracy: 0.6201\n",
            "Epoch 74/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.7916 - accuracy: 0.6236\n",
            "Epoch 75/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.7608 - accuracy: 0.6312\n",
            "Epoch 76/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.7368 - accuracy: 0.6428\n",
            "Epoch 77/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.7251 - accuracy: 0.6367\n",
            "Epoch 78/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.7105 - accuracy: 0.6473\n",
            "Epoch 79/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 1.6857 - accuracy: 0.6488\n",
            "Epoch 80/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.6490 - accuracy: 0.6554\n",
            "Epoch 81/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.6395 - accuracy: 0.6529\n",
            "Epoch 82/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.6747 - accuracy: 0.6483\n",
            "Epoch 83/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.6353 - accuracy: 0.6604\n",
            "Epoch 84/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.5819 - accuracy: 0.6655\n",
            "Epoch 85/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.5454 - accuracy: 0.6751\n",
            "Epoch 86/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.5167 - accuracy: 0.6801\n",
            "Epoch 87/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.4864 - accuracy: 0.6837\n",
            "Epoch 88/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.4668 - accuracy: 0.6937\n",
            "Epoch 89/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.4521 - accuracy: 0.6973\n",
            "Epoch 90/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 1.4201 - accuracy: 0.6948\n",
            "Epoch 91/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 1.4063 - accuracy: 0.6998\n",
            "Epoch 92/200\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 1.3847 - accuracy: 0.7033\n",
            "Epoch 93/200\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 1.3632 - accuracy: 0.7114\n",
            "Epoch 94/200\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 1.3458 - accuracy: 0.7114\n",
            "Epoch 95/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.3372 - accuracy: 0.7149\n",
            "Epoch 96/200\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 1.3335 - accuracy: 0.7079\n",
            "Epoch 97/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 1.3022 - accuracy: 0.7230\n",
            "Epoch 98/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 1.2837 - accuracy: 0.7200\n",
            "Epoch 99/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.2637 - accuracy: 0.7245\n",
            "Epoch 100/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.2465 - accuracy: 0.7286\n",
            "Epoch 101/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.2312 - accuracy: 0.7301\n",
            "Epoch 102/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.2077 - accuracy: 0.7412\n",
            "Epoch 103/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.1943 - accuracy: 0.7452\n",
            "Epoch 104/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.1790 - accuracy: 0.7447\n",
            "Epoch 105/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.1822 - accuracy: 0.7417\n",
            "Epoch 106/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.1485 - accuracy: 0.7503\n",
            "Epoch 107/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.1291 - accuracy: 0.7603\n",
            "Epoch 108/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.1220 - accuracy: 0.7588\n",
            "Epoch 109/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.1147 - accuracy: 0.7528\n",
            "Epoch 110/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.0877 - accuracy: 0.7563\n",
            "Epoch 111/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.0690 - accuracy: 0.7639\n",
            "Epoch 112/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.0556 - accuracy: 0.7719\n",
            "Epoch 113/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.0396 - accuracy: 0.7770\n",
            "Epoch 114/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.0323 - accuracy: 0.7785\n",
            "Epoch 115/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.0334 - accuracy: 0.7740\n",
            "Epoch 116/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 1.0151 - accuracy: 0.7775\n",
            "Epoch 117/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 1.0037 - accuracy: 0.7800\n",
            "Epoch 118/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.9932 - accuracy: 0.7815\n",
            "Epoch 119/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.9808 - accuracy: 0.7825\n",
            "Epoch 120/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.9716 - accuracy: 0.7820\n",
            "Epoch 121/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9494 - accuracy: 0.7876\n",
            "Epoch 122/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9336 - accuracy: 0.7901\n",
            "Epoch 123/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9201 - accuracy: 0.7906\n",
            "Epoch 124/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9062 - accuracy: 0.7947\n",
            "Epoch 125/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8971 - accuracy: 0.7972\n",
            "Epoch 126/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8878 - accuracy: 0.7982\n",
            "Epoch 127/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8812 - accuracy: 0.7972\n",
            "Epoch 128/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8816 - accuracy: 0.7972\n",
            "Epoch 129/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8738 - accuracy: 0.8002\n",
            "Epoch 130/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8767 - accuracy: 0.7962\n",
            "Epoch 131/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8706 - accuracy: 0.7977\n",
            "Epoch 132/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8842 - accuracy: 0.7906\n",
            "Epoch 133/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8840 - accuracy: 0.7866\n",
            "Epoch 134/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8671 - accuracy: 0.7941\n",
            "Epoch 135/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8405 - accuracy: 0.8017\n",
            "Epoch 136/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8285 - accuracy: 0.8002\n",
            "Epoch 137/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8171 - accuracy: 0.8093\n",
            "Epoch 138/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8028 - accuracy: 0.8047\n",
            "Epoch 139/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7807 - accuracy: 0.8128\n",
            "Epoch 140/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7796 - accuracy: 0.8158\n",
            "Epoch 141/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7766 - accuracy: 0.8163\n",
            "Epoch 142/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7624 - accuracy: 0.8174\n",
            "Epoch 143/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.7539 - accuracy: 0.8189\n",
            "Epoch 144/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.7470 - accuracy: 0.8224\n",
            "Epoch 145/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.7380 - accuracy: 0.8239\n",
            "Epoch 146/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.7284 - accuracy: 0.8264\n",
            "Epoch 147/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.7209 - accuracy: 0.8320\n",
            "Epoch 148/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7120 - accuracy: 0.8325\n",
            "Epoch 149/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.7037 - accuracy: 0.8340\n",
            "Epoch 150/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6986 - accuracy: 0.8360\n",
            "Epoch 151/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6926 - accuracy: 0.8330\n",
            "Epoch 152/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6875 - accuracy: 0.8411\n",
            "Epoch 153/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6783 - accuracy: 0.8431\n",
            "Epoch 154/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6702 - accuracy: 0.8416\n",
            "Epoch 155/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6627 - accuracy: 0.8426\n",
            "Epoch 156/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6613 - accuracy: 0.8461\n",
            "Epoch 157/200\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.6852 - accuracy: 0.8391\n",
            "Epoch 158/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.6783 - accuracy: 0.8421\n",
            "Epoch 159/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.7346 - accuracy: 0.8269\n",
            "Epoch 160/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6997 - accuracy: 0.8310\n",
            "Epoch 161/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6731 - accuracy: 0.8365\n",
            "Epoch 162/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6555 - accuracy: 0.8426\n",
            "Epoch 163/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6441 - accuracy: 0.8421\n",
            "Epoch 164/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6256 - accuracy: 0.8542\n",
            "Epoch 165/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6133 - accuracy: 0.8527\n",
            "Epoch 166/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6049 - accuracy: 0.8552\n",
            "Epoch 167/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5986 - accuracy: 0.8507\n",
            "Epoch 168/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.5927 - accuracy: 0.8512\n",
            "Epoch 169/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.5866 - accuracy: 0.8607\n",
            "Epoch 170/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.5834 - accuracy: 0.8582\n",
            "Epoch 171/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.5786 - accuracy: 0.8572\n",
            "Epoch 172/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5710 - accuracy: 0.8582\n",
            "Epoch 173/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5769 - accuracy: 0.8602\n",
            "Epoch 174/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5961 - accuracy: 0.8512\n",
            "Epoch 175/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5878 - accuracy: 0.8507\n",
            "Epoch 176/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5910 - accuracy: 0.8496\n",
            "Epoch 177/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5843 - accuracy: 0.8522\n",
            "Epoch 178/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6239 - accuracy: 0.8385\n",
            "Epoch 179/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5717 - accuracy: 0.8527\n",
            "Epoch 180/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5578 - accuracy: 0.8562\n",
            "Epoch 181/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5465 - accuracy: 0.8658\n",
            "Epoch 182/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5411 - accuracy: 0.8658\n",
            "Epoch 183/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5305 - accuracy: 0.8663\n",
            "Epoch 184/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.5250 - accuracy: 0.8638\n",
            "Epoch 185/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5283 - accuracy: 0.8648\n",
            "Epoch 186/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5319 - accuracy: 0.8607\n",
            "Epoch 187/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5164 - accuracy: 0.8668\n",
            "Epoch 188/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5092 - accuracy: 0.8668\n",
            "Epoch 189/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5021 - accuracy: 0.8703\n",
            "Epoch 190/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4981 - accuracy: 0.8713\n",
            "Epoch 191/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4949 - accuracy: 0.8708\n",
            "Epoch 192/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4904 - accuracy: 0.8713\n",
            "Epoch 193/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4881 - accuracy: 0.8713\n",
            "Epoch 194/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.4952 - accuracy: 0.8708\n",
            "Epoch 195/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.4862 - accuracy: 0.8744\n",
            "Epoch 196/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.4980 - accuracy: 0.8718\n",
            "Epoch 197/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.4869 - accuracy: 0.8724\n",
            "Epoch 198/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4946 - accuracy: 0.8638\n",
            "Epoch 199/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4865 - accuracy: 0.8744\n",
            "Epoch 200/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5284 - accuracy: 0.8557\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
        "model.add(Bidirectional(LSTM(20)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(input_sequences, one_hot_labels, epochs=200, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXVFpoREhV6Y"
      },
      "source": [
        "### View the Training Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "aeSNfS7uhch0",
        "outputId": "5a5e1b93-2329-4f92-c37e-7c6abe2f4da4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.show()\n",
        "\n",
        "plot_graphs(history, 'accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rAgRpxYhjpB"
      },
      "source": [
        "### Generate new lyrics!\n",
        "\n",
        "It's finally time to generate some new lyrics from the trained model, and see what we get. To do so, we'll provide some \"seed text\", or an input sequence for the model to start with. We'll also decide just how long of an output sequence we want - this could essentially be infinite, as the input plus the previous output will be continuously fed in for a new output word (at least up to our max sequence length)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "DC7zfcgviDTp",
        "outputId": "34a5eb15-9094-463f-9864-80c99b89758a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 944ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "im feeling chills me to the bone is dead take me down in the fate out kind had boomaboomerang bang were eyes blue wanted never crazy eyes ground ground meant wanted wanted wanted wanted wanted wanted wanted wanted wanted wanted wanted wanted wanted know tiny crazy eyes advice but never do but but day hours so come without my making its its its around before a new am but but on on on please boomerang lord our bang peace blue crazy world do but cry so on up meant god had boomaboomerang god crazy would ground meant never life showing meant had wanted\n"
          ]
        }
      ],
      "source": [
        "seed_text = \"im feeling chills\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted = np.argmax(model.predict(token_list), axis=-1)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "l10c03_nlp_constructing_text_generation_model.ipynb",
      "toc_visible": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}